<!DOCTYPE html>

<html lang="en-us"><head>
	<meta name="generator" content="Hugo 0.103.1" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css"
        integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

    <link rel="stylesheet"
        href="https://fonts.googleapis.com/css2?family=Nanum+Myeongjo&family=Noto+Serif+JP&family=Cormorant+Garamond&family=Libre+Baskerville&family=Source+Serif+Pro&family=Crimson+Text&family=Inter&family=Crimson+Pro&family=Literata&family=Ubuntu+Mono&family=Inter&family=Roboto">
    <link rel="stylesheet" type="text/css" href="/css/style.css">

    
    

    <title>SCHOLAR | LINKAI PENG</title>


    

</head><body class="container d-flex flex-column min-vh-100">















<div class="row w-100">
    <div class="col w-100">
        

<div class="about row w-100">
    



<div class="row w-100 justify-content-center">
    <img class="rounded-circle  " src="images/profile.png" alt="profile_picture" id="profile_picture" />
</div>



<div class=" row w-100 justify-content-center main_color" id="full_name">
    PENG LINKAI
</div>



<div class="affiliations row w-100 justify-content-center">
    <div class="row w-100 justify-content-center">
        
        <div class="row w-100 justify-content-center" id="title-name">
            <span class="main_color" id="title">
                Artificial Intelligence Engineer,
            </span>
            <span id="name" class="text-muted">
                NetEase
            </span>
        </div>
        <div class="row w-100 justify-content-center text-muted" id="email">
            penglk@rd.netease.com | penglinkai96@gmail.com
        </div>


        
    </div>
</div>



<div class="socials row w-100  justify-content-center">
    <div class="row w-100 justify-content-center">
        
        
        
        
        
        
        
        
        


        
        <a href='https://www.researchgate.net/profile/Peng-Linkai-3' target="_blank">
            <div class="main_color dates col-md-auto justify-content-end" font-size=>
                Research Gate
            </div>
        </a>
        

        
        <a href='https://scholar.google.com/citations?user=v8G7pHoAAAAJ' target="_blank">
            <div class="main_color dates col-md-auto justify-content-end" font-size=>
                Google Scholar
            </div>
        </a>
        

        
        <a href='https://github.com/vocaliodmiku' target="_blank">
            <div class="main_color dates col-md-auto justify-content-end" font-size=>
                Github
            </div>
        </a>
        

        
        <a href='LinkaiPeng.pdf' target="_blank">
            <div class="main_color dates col-md-auto justify-content-end" font-size=>
                CV
            </div>
        </a>
        


    </div>
</div>



<div class="introduction row w-100 text-justify">
    <div class="col w-100">
        <p>Hi, this is Linkai Peng. I am an ML engineer @ NetEase YouDao. I am passionate about using cutting-edge ML technologies to boost the spoken Human-Computer Interaction system. A central focus of my current work is developing self-supervised neural networks to improve our ASR related <a href="https://smart.youdao.com/en/">industry products</a>, including ASR, CAPT. I also have an interest in analyses that lie in cross-language perception and production, e.g. the comprehension of L2 speech.</p>

    </div>
</div>

</div>

<div class="about row w-100">
    





<div class="interests col ">
    <h4 class="main_color">Interests</h4>
    <ul>
        
        <li>
            Automatic Speech Recognition (ASR)
        </li>
        
        <li>
            Computer-Assisted Pronunciation Training (CAPT)
        </li>
        
        <li>
            Speech Production and Comprehension
        </li>
        
        <li>
            Multimodal analysis of Audio-Lexical content
        </li>
        
    </ul>
</div>



<div class="academia col">
    <h4 class="main_color">Academia</h4>
    
    <div class="row">
        <div class="course col">
            <div class="institution_dates row">
                <div class="institution col" id="institution_title">
                    Beijing Language and Culture University
                </div>
                <div class="main_color dates col-md-auto  justify-content-end">
                    2019
                    
                    - 2022
                    
                </div>
            </div>
            <div class="degree_major row">
                <div class="text-muted col">
                    M.Eng. Software Engineering

                    
                </div>
            </div>

            
            <div class="other_info row text-muted">
                <div class="col">
                    graduated with Outstanding Graduation Dissertation Award, supervised by Prof. Jinsong Zhang!
                </div>
            </div>
            
        </div>
    </div>
    
    <div class="row">
        <div class="course col">
            <div class="institution_dates row">
                <div class="institution col" id="institution_title">
                    South China Normal University
                </div>
                <div class="main_color dates col-md-auto  justify-content-end">
                    2015
                    
                    - 2019
                    
                </div>
            </div>
            <div class="degree_major row">
                <div class="text-muted col">
                    B.Sc. Physics

                    
                </div>
            </div>

            
        </div>
    </div>
    
</div>


</div>

</div>
</div>
















<div class="row w-100">
    <div class="col w-100">
        
        <div class="row w-100">
            <div class="col w-100">
                
                <h3 class="row  w-100 section-title main_color"> Experiences </h3>
                

                
            </div>
        </div>
        













<div class="news row w-100">
    <div class="col w-100">
        <ul class="news_list">
            
            

            <li>
                
                <i data-feather="briefcase"></i>
                

                
                NetEase YouDao, full-time Artificial Intelligence Engineer
                

                
                <span class="secondary_font text-muted">, April 2022 - Now.</span>
                

            </li>
            
            

            <li>
                
                <i data-feather="briefcase"></i>
                

                
                ByteDance AI-Lab, Speech Technology Research Intern
                

                
                <span class="secondary_font text-muted">, November. 2020 - February. 2021</span>
                

            </li>
            
        </ul>
    </div>
</div></div>
</div>




















<div class="row w-100">
    <div class="col w-100">
        
        <div class="row w-100">
            <div class="col w-100">
                
                <h3 class="row  w-100 section-title main_color"> Recent Publications </h3>
                

                
                <h6 class="row w-100 section-subtitle  text-muted"> see my research gate for the latest list </h6>
                
            </div>
        </div>
        





<div class="publications row w-100">
    <div class="col w-100">
        
        <div class="publication row  w-100">

            <div class="section-1 w-100">
                <span>
                    A Study on Fine-Tuning wav2vec2. 0 Model for the Task of Mispronunciation Detection and Diagnosis.,
                </span>

                <span class="text-muted publication-date">
                    
                </span>

                <span class="text-muted publication-name">
                    Interspeech 2021.
                </span>

            </div>

            <div class="section-2 text-muted w-100">

                

                
                
                <span>
                    Linkai Peng
                </span>
                
                <span class="separator">
                    ,
                </span>
                
                
                <span>
                    Kaiqi Fu
                </span>
                
                <span class="separator">
                    ,
                </span>
                
                
                <span>
                    Binghuai Lin
                </span>
                
                <span class="separator">
                    ,
                </span>
                
                
                <span>
                    Dengfeng Ke
                </span>
                
                <span class="separator">
                    ,
                </span>
                
                
                <span>
                    Jinsong Zhang
                </span>
                
                
                

            </div>

            
            
            <div class="section-3  w-100">
                
                    
                <a class="main_color text-decoration-none rounded" href="https://github.com/vocaliodmiku/wav2vec2mdd" target="_blank">
                    code
                </a>
                    
                
                    
                <a class="main_color text-decoration-none rounded" href="https://www.isca-speech.org/archive/pdfs/interspeech_2021/peng21e_interspeech.pdf" target="_blank">
                    pdf
                </a>
                    
                
            </div>
            



        </div>

        
        <div class="publication row  w-100">

            <div class="section-1 w-100">
                <span>
                    An Exploratory Study for Quantifying the Contextual Information for Successful Chinese L2 Speech Comprehension.,
                </span>

                <span class="text-muted publication-date">
                    
                </span>

                <span class="text-muted publication-name">
                    ISCSLP 2022
                </span>

            </div>

            <div class="section-2 text-muted w-100">

                

                
                
                <span>
                    Rian Bao
                </span>
                
                <span class="separator">
                    ,
                </span>
                
                
                <span>
                    Lin Peng
                </span>
                
                <span class="separator">
                    ,
                </span>
                
                
                <span>
                    Yuchen Yan
                </span>
                
                <span class="separator">
                    ,
                </span>
                
                
                <span>
                    Jinsong Zhang
                </span>
                
                
                

            </div>

            
            
            <div class="section-3  w-100">
                
                    
                <a class="main_color text-decoration-none rounded" href="https://boroooo.github.io/pdfs/Exploratory_RianBao.pdf" target="_blank">
                    pdf
                </a>
                    
                
            </div>
            



        </div>

        
        <div class="publication row  w-100">

            <div class="section-1 w-100">
                <span>
                    Multi-scale model for mandarin tone recognition,
                </span>

                <span class="text-muted publication-date">
                    
                </span>

                <span class="text-muted publication-name">
                    ISCSLP 2021
                </span>

            </div>

            <div class="section-2 text-muted w-100">

                

                
                
                <span>
                    Linkai Peng
                </span>
                
                <span class="separator">
                    ,
                </span>
                
                
                <span>
                    Wang Dai
                </span>
                
                <span class="separator">
                    ,
                </span>
                
                
                <span>
                    Dengfeng Ke
                </span>
                
                <span class="separator">
                    ,
                </span>
                
                
                <span>
                    Jinsong Zhang
                </span>
                
                
                

            </div>

            
            



        </div>

        
        <div class="publication row  w-100">

            <div class="section-1 w-100">
                <span>
                    Text-Aware End-to-end Mispronunciation Detection and Diagnosis,
                </span>

                <span class="text-muted publication-date">
                    
                </span>

                <span class="text-muted publication-name">
                    Preprint 2022.
                </span>

            </div>

            <div class="section-2 text-muted w-100">

                

                
                
                <span>
                    Linkai Peng
                </span>
                
                <span class="separator">
                    ,
                </span>
                
                
                <span>
                    Yingming Gao
                </span>
                
                <span class="separator">
                    ,
                </span>
                
                
                <span>
                    Binghuai Lin
                </span>
                
                <span class="separator">
                    ,
                </span>
                
                
                <span>
                    Dengfeng Ke
                </span>
                
                <span class="separator">
                    ,
                </span>
                
                
                <span>
                    Yanlu Xie
                </span>
                
                <span class="separator">
                    ,
                </span>
                
                
                <span>
                    Jinsong Zhang
                </span>
                
                
                

            </div>

            
            
            <div class="section-3  w-100">
                
                    
                <a class="main_color text-decoration-none rounded" href="https://github.com/vocaliodmiku/wav2vec2mdd-Text" target="_blank">
                    code
                </a>
                    
                
                    
                <a class="main_color text-decoration-none rounded" href="https://arxiv.org/pdf/2206.07289.pdf" target="_blank">
                    pdf
                </a>
                    
                
            </div>
            



        </div>

        
        <div class="publication row  w-100">

            <div class="section-1 w-100">
                <span>
                    The Contribution of Phonological and Fluency Factors to Chinese L2 Comprehensibility Ratings: A Case Study of Urdu-speaking Learners.,
                </span>

                <span class="text-muted publication-date">
                    
                </span>

                <span class="text-muted publication-name">
                    ISCSLP 2021
                </span>

            </div>

            <div class="section-2 text-muted w-100">

                

                
                
                <span>
                    Rian Bao
                </span>
                
                <span class="separator">
                    ,
                </span>
                
                
                <span>
                    Linkai Peng
                </span>
                
                <span class="separator">
                    ,
                </span>
                
                
                <span>
                    Gingming Gao
                </span>
                
                <span class="separator">
                    ,
                </span>
                
                
                <span>
                    Jinsong Zhang
                </span>
                
                
                

            </div>

            
            
            <div class="section-3  w-100">
                
                    
                <a class="main_color text-decoration-none rounded" href="https://boroooo.github.io/pdfs/Contribution_RianBao.pdf" target="_blank">
                    pdf
                </a>
                    
                
            </div>
            



        </div>

        

    </div>
    
</div>
</div>
</div>
















<div class="row w-100">
    <div class="col w-100">
        
        <div class="row w-100">
            <div class="col w-100">
                
                <h3 class="row  w-100 section-title main_color"> Projects </h3>
                

                
            </div>
        </div>
        





  
<div class="projects row w-100">
    <div class="col w-100">
        
        <div class="project row w-100">
            <div class="section-1 w-100">
                <span class="project-title" style="font-weight:600">
                    Self-supervised pretraining technology for multi-model processing
                </span>
            </div>
            <section style="margin-top:1%;display:flex;">
                    <img style="float:left;margin-right:2em;" width="520x" height="320px" src="images/wav2vec.svg"></img> 
                    <p style="margin-left:2px;font-size:small;">
                        In speech processing especially, we are urged to utlize large scale unlabeled acoustic data. <a href="https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/">Wav2vec 2.0</a> is set tackle that. It is trained by predicting high-level contextualized speech representations which can describe many different speech audio recordings and non-speech (we have verified its outstanding performance on <a href="https://en.wikipedia.org/wiki/Voice_activity_detection">VAD</a>). What&rsquo;s more, low-resource languages can improve significantly with cross-lingual training. After the huge success of Wav2vec 2.0, many new methods to apply self-supervised learning to acoustic data come out, e.g. UniSpeech, HuBERT, WavLM, etc. Another line of works are pay attention to multi-model processing. Data2vec aims to bridge the gap between different self-supervised learning algorithms for images, speech, text or other modalities function, and develops a unified way to generate representations in a common feature space. </br>
                        In practice, we have found that it&rsquo;s not easy to train an ASR model with a train-from-scratch decoder. Multi-model self-supervised learning can help the text modality decoder generalize fast. Currently we are exploring these technology for more possibilties. </br>
                        <em>[picture come from <a href="https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/">here</a>]</em>
                    </p>

            </section>

            
            


        </div>
        
        <div class="project row w-100">
            <div class="section-1 w-100">
                <span class="project-title" style="font-weight:600">
                    Toward fine-grained feedback for Mispronunciation Detection and Diagnosis
                </span>
            </div>
            <section style="margin-top:1%;display:flex;">
                    <img style="float:left;margin-right:2em;" width="520px" height="360px" src="images/mdd.png"></img> 
                    <p style="margin-left:2px;font-size:small;">
                        Mispronunciation detection and diagnosis (MDD) technology is a key component of computer-assisted pronunciation training system (CAPT). The mainstream method is based on deep neural network automatic speech recognition. Many works and applications focus on the pronunciation score and neglect the meaningful feedback. We are going to deploy a system based on multi-model self-supervised learning for education toward fine-grained feedback, such as articulatory feedback. The CAPT system can be enhanced by providing articulatory feedback about the pronunciation error in addition to detecting and recognizing. We aim to develop deep learning based techniques to understand how human learn to speak a second language and in what way we can integrate automatic speech technology into this process. </br>
                         </br>
                        <em>[picture come from <a href="https://www.youtube.com/watch?v=Z_Q1tC1hN_A">here</a>]</em>
                    </p>

            </section>

            
            


        </div>
        


    </div>
    
</div>
</div>
</div>







<footer class="mt-auto d-flex justify-content-center text-muted small secondary_font">
    <span class="text-muted">Copyright (c) 2022, LINKAI PENG,
        <a class="text-muted" href="https://github.com/hadisinaee/avicenna" target="_blank"> created by Avicenna
            (MIT)</a>
    </span>
</footer><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx"
    crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/feather-icons/4.28.0/feather.min.js"></script>
<script>
    feather.replace()
</script></body>

</html>