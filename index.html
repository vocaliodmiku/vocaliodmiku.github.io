<!DOCTYPE HTML
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3c.org/TR/1999/REC-html401-19991224/loose.dtd">
<html>

<head>
  <!-- <div class="navbar">
		<a href="./index.html"><font size="+1">Home</font></a>
		<a href="./publication.html"><font size="+1">Publications</font></a>
    <a href="./teach.html"><font size="+1">Teaching</font></a>
    <a href="./awards.html"><font size="+1">Awards</font></a>
		<a href="./misc.html"><font size="+1">Misc</font></a>
	</div> -->
  <title>Linkai Peng</title>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
  <link rel="stylesheet" type="text/css" href="style.css" />
</head>

<body style="color: rgba(0, 0, 0, 0.938);margin:0;padding:0">
  <div id="wrapper">
    <div id="content-wrap">
      <div id="content">
        <div id="main">
          <tr>
            <p style="padding-right:30px;"> <img id="headshot" "float-left" align="left" alt="plk"
                src="images/profile.png" width="180" height="185" /></p>

            <p>
              <font size="+3"><strong>&nbsp;Linkai Peng</strong></font>
            </p>
            <p></p>
            <p style="line-height:90%">
              <font size="3"><a href="" style="color:#9B0145;">&nbsp;&nbsp;NetEase Youdao</a></font>
            </p>
            <p style="line-height:90%">
              <font size="3">&nbsp;&nbsp;Beijing, China</font>
            </p>
            <p style="line-height:90%">
              <font size="3"><strong>&nbsp;&nbsp;Email:</strong> penglinkai96@gmail.com | penglinkai@corp.netease.com
              </font>
            </p>

            <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons/css/academicons.min.css">
            &nbsp;&nbsp;&nbsp;&nbsp;<a href="https://scholar.google.com/citations?user=v8G7pHoAAAAJ"><i
                class="ai ai-google-scholar ai-2x" style="font-size:26px; color:#9B0145">&nbsp;</i></a>
            <link rel="stylesheet"
              href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
            <a href="https://github.com/vocaliodmiku"><i class="fa fa-github"
                style="font-size:26px; color:#9B0145">&nbsp;</i></a>
            <a href='https://www.researchgate.net/profile/Peng-Linkai-3'><i class="ai ai-researchgate ai-2x"
                style="font-size:26px; color:#9B0145">&nbsp;</i></a>
            <a href='pdfs/LinkaiPeng.pdf'><i class="ai ai-cv ai-2x"
                style="font-size:26px; color:#9B0145">&nbsp;</i></a>
            <!-- <p></p> -->
          </a>
          </tr>
          <hr style="color:rgb(218, 218, 218);">

          <h1><a name="biography">About Me</h1>
          <p>Hi, this is Linkai Peng. I am an ML engineer @ NetEase YouDao, where a central focus of my work is
            <a style="color:#b04605;">developing machine learning models and applying linguistic knowledge to improve Language Learning system for Chinese English Learner. </a>
            Recently, I am developing a Conversational AI teacher for language learning. I am curious
            about <b> the process of human/machine speech perception </b>. My research interests intersect in the areas
            of <b> speech processing, phonetics, second language acquisition, neuroscience, and cognitive science.</b>
            <!-- <p style="font-size:16px">&#11088; I will join the <a href="https://csweb.rice.edu/" style="color:#01569b;">Department of Computer Science @ Rice University</a> as a tenure-track Assistant Professor starting July 2024. I'm actively looking for motivated students to join my group. Please feel free to reach out (<a style="color:#01569b;">hanjie@rice.edu</a>) if you are interested in collaborating or working with me.</p>
	  <p style="font-size:16px">&#128293; <a style="color:#d93b3b;"><b>Prospective students</b></a>: I am recruiting 1-2 PhD students for Fall 2024. Please apply to our <a href="https://csweb.rice.edu/academics/graduate-programs/graduate-admission" style="color:#01569b;">graduate programs</a>.</p>    -->
          <dl style="background-color:#b9a2100f">
            <p></p>
            <p style="font-size:18px">&#128204; <a style="color:#6c3a3af2;"><b>Research Themes Overview</b></a></p>
            <div class="twocol">
              <div class="leftcol">
                <p style="padding-left:0px;margin-bottom: 0;margin-top: 0"><img src="images/642.png" width="450"
                    style="border: 0;"></p>
                <p style="color:#cccccc;margin-top: 0px;font-size: 8px;">Image from: Li, Y., Anumanchipalli, G.,
                  Mohamed, A., Chen, P., Carney, L. H., Lu, J., Wu, J., Chang, E.F. (2023) Dissecting neural
                  computations of the human auditory pathway using deep neural networks for speech. Nature Neuroscience,
                  26, 1-30.</p>
              </div>
              <div class="rightcol">
                <ul style="overflow: hidden; padding-right:10px;">
                  <!-- <li> <b>How to understand black-box models?</b>
                    <br><a>
                      <font size="2">We develop explanation methods to explain model
                        <b>predictions</b> (<a href="http://aclanthology.lst.uni-saarland.de/2020.acl-main.494.pdf"
                          style="color:#b04605;">ACL'2020</a>,
                        <a href="https://aclanthology.org/2021.naacl-main.306.pdf"
                          style="color:#b04605;">NAACL'2021</a>)
                        and <b>uncertainty</b> (<a href="https://arxiv.org/pdf/2201.03742.pdf"
                          style="color:#b04605;">AAAI-UDM'2023</a>)
                        and evaluate explanations to understand model <b>reasoning</b> (<a
                          href="https://arxiv.org/pdf/2210.04982.pdf" style="color:#b04605;">ACL'2023</a>)
                        and <b>robustness</b> (<a href="https://arxiv.org/pdf/2212.05327.pdf"
                          style="color:#b04605;">BlackboxNLP'2022</a>,
                        <a href="https://arxiv.org/pdf/2108.04990.pdf" style="color:#b04605;">2021</a>).
                      </font>
                    </a> -->
                  <li> <b>How do humans perceive and process speech?</b>
                    <br><a>
                      <font size="2">We investigated the contribution of several acoustic parameters (<b>phonological and fluency</b> (<a href="https://www.colips.org/conferences/iscslp2022/Proceedings/papers/ISCSLP2022_P092.pdf"
                        style="color:#b04605;">Rian et al.'2022</a>), <b>lexical tone</b> (<a href="https://www.colips.org/conferences/ialp2022/proceedings/papers/IALP2022_P119.pdf"
                        style="color:#b04605;">Rian et al.'2022</a>), and <b>contextual information</b> (<a href="https://www.colips.org/conferences/iscslp2022/Proceedings/papers/ISCSLP2022_P123.pdf"
                        style="color:#b04605;">Rian et al.'2022</a>)) to the comprehensibility of second language speech through <b>behavioral experiments</b> and <b>Functional Load Principle</b>.
                      </font>
                    </a>


                  <li> <b>Do deep learning to have similar speech processing mechanisms as the human brain? (or is it necessary)</b>
                    <br><a>
                      <font size="2">Advanced deep learning models have brought new research paradigms to the exploration of how the human brain processes speech. Many studies have found a strong alignment between the hierarchical representations of <b>self-supervised speech models</b> and <b>the neural activity in human auditory pathway</b> (left picture). (<a href="https://vocaliodmiku.github.io/deep-speech-model-and-human-brain/" style="color:#b04605;">Project #1'2023</a><a href="https://vocaliodmiku.github.io/deep-speech-model-and-human-brain/index_cn.html" style="color:#b04605;"> / 中文 </a>)
                      </font>
                    </a>
                    
                  <li> <b>How to recover speech/semantic information from brain recordings? </b>
                    <br><a>
                      <font size="2">Intracranial recordings have made significant advancements in this area while the challenge of decoding speech from non-invasive brain recordings remains. (<a href="https://vocaliodmiku.github.io/recover-speech-information-from-brain-recordings/" style="color:#b04605;">Project #2'2023</a>).
                      </font>
                    </a>
                </ul>
              </div>
            </div>

            <a style="color:#6c3a3af2; font-size:18px"><b>&nbsp;&nbsp; &#10024; Past Research Themes</b></a>
            <ul>
              <li> <font size="3"> <b>Non-native Speech Processing:</b> Mispronunciation detection and diagnosis with self supervised model. (<a
                href="https://isca-speech.org/archive/pdfs/interspeech_2021/peng21e_interspeech.pdf" style="color:#b04605;">Linkai et al'2021;</a><a
                href="https://arxiv.org/pdf/2206.07289" style="color:#b04605;">2022</a></font>)
              <li> <b>Mandarin Tone Recognition:</b> modeling tone with multi-scale temporal-frequency features. (<a
                href="https://www.researchgate.net/profile/Peng-Linkai-3/publication/349802146_Multi-Scale_Model_for_Mandarin_Tone_Recognition/links/647412aca25e543829daa199/Multi-Scale-Model-for-Mandarin-Tone-Recognition.pdf" style="color:#b04605;">Linkai et al'2020;</a>)
            </ul>
          </dl>

          <!-- <dl style="background-color:#b953100c">
            <p></p>
            <p style="font-size:18px"> <a style="color:#6c3a3af2;"><b>Highlights</b></a></p>
            <p style="font-size:16px">&#127891; Received the Outstanding Doctoral Student Award, UVA, 2023</p>
            <p style="font-size:16px">&#127881; Received the John A. Stankovic Graduate Research Award, UVA, 2023</p>
            <p style="font-size:16px">&#127881; I was awarded the Carlos and Esther Farrar Fellowship, 2022 - 2023</p>
            <p style="font-size:16px">&#128105;&#8205;&#127979; As the primary instructor, I co-designed and taught the
              course, <a href="https://uvanlp.org/iml-2022/" target="_blank" style="color:#9B0145;">CS 6501/4501
                Interpretable Machine Learning</a>, at UVA in Spring 2022, and was awarded the UVA CS Outstanding
              Graduate Teaching Award and University-wide Graduate Teaching Awards Nominee (<b>top 5%</b> of graduate
              instructors)</p>
            <p style="font-size:16px">&#128221; My collaborators and I are actively updating a <a
                href="https://github.com/HanjieChen/Reading-List/wiki" style="color:#9B0145;">Reading List</a> with
              interesting papers</p>
            <p></p>
          </dl> -->

          <dl style="background-color:rgba(230, 199, 243, 0.13)">
            <p></p>
            <a style="color:#6c3a3af2; font-size:18px"><b>&nbsp;&nbsp;Updates</b></a>
            <div class="myBox">
              <ul>
                <li> [11/2023] The setup of two research project pages has been completed [<a href="https://vocaliodmiku.github.io/deep-speech-model-and-human-brain/" style="color:#b04605;">Project #1'2023</a><a href="https://vocaliodmiku.github.io/deep-speech-model-and-human-brain/index_cn.html" style="color:#b04605;"> / 中文 </a>| <a href="https://vocaliodmiku.github.io/recover-speech-information-from-brain-recordings/" style="color:#b04605;">Project #2'2023</a>]. If you have similar research interests and relevant background (computer science, cognitive science, and linguistics), please feel free to take a look at them and any suggestions are greatly appreciated.

                <li> [08/2023] New preprint [<a
                  href="https://arxiv.org/pdf/2308.14536.pdf" style="color:#9B0145;">ArXiv</a> | <a
                  href="https://vocaliodmiku.github.io/SLI-LL/" style="color:#9B0145;"> Website</a>], <i>Spoken Language Intelligence of Large Language Models for Language Learning</i>, We conducted preliminary explorations on large language models and confirmed through various prompts that text-based large language models (LLM, e.g. ChatGPT, GPT4, LLaMa2) have a good understanding of concepts in phonetics, phonology, and second language acquisition. <br><b>We look forward to LLM with speech input in their performance in neurolinguistics!</b>
              </ul>
            </div>
          </dl>

          <p></p>
          <h1><a name="activities">Research Experience</h1>
          <!-- <b><font size="+1">&nbspService</b> -->
          <ul>
            <li> <b>NetEase</b>, Beijing, China, July 2022 - Now
              <p><i>YouDao Group</i></p>
              <ul>
                <li> Artificial Intelligence Engineer
              </ul>
            <li> <b>ByteDance AI-Lab</b>, Beijing, China, November. 2020 - February. 2021
              <p><i> </i></p>
              <ul>
                <li> Research Intern
              </ul>
            <li> <b>Beijing Language and Culture University</b>, Beijing, China, September. 2019 - June. 2022
              <p><i>Speech Acquisition and Intelligent Technology Lab</i></p>
              <ul>
                <li> Research Assistant
          </ul>
          <!-- <h1><a name="activities">Professional Service</h1>
          <!-- <b><font size="+1">&nbspService</b>  
          <ul>
            <li> <b>Organizer</b>: BlackboxNLP 2024
            <li> <b>Diversity Representative</b> for UVA Computer Science Graduate Student Group (CSGSG) Council, 2022
            <li> <b>Area Chair</b> for WiML Workshop @ NeurIPS 2022
            <li> <b>Program Committee</b>: ACL 2023, AAAI 2023, EMNLP 2021 - 2023, NAACL 2021, EACL 2023, CoNLL 2021 -
              2022, NLPCC 2022, ACL DialDoc Workshop 2022, EMNLP BlackboxNLP Workshop 2021, 2023, NeurIPS Explainable AI
              Approaches for Debugging and Diagnosis Workshop 2021, Document-grounded Dialogue Workshop 2021, MASC-SLL
              2020
            <li> <b>Reviewer</b>: TACL 2023 - 2025, ICLR 2024, NeurIPS 2023, EMNLP 2023, ACL Rolling Review 2021 - now,
              ACL 2020 - 2021, EMNLP BlackboxNLP Workshop 2022, CoNLL 2019 - 2020, NLPCC 2019 - 2021
          </ul> -->

          <hr style="color:rgb(218, 218, 218);">
          <div style="text-align: center; font-size: 18px;"><small>Last update: 11/2023. Modified from Website of <a href="https://github.com/HanjieChen/hanjiechen.github.io" style="color:#9B0145;">Prof. Hanjie Chen</a> </small>
          </div>
          <br>
        </div>
      </div>
    </div>
  </div>

</body>

</html>